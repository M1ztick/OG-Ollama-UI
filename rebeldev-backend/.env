# ==========================
# OG-Ollama-UI Backend Configuration
# ==========================

# --- Server ---
HOST=127.0.0.1           # Use localhost behind NGINX proxy
PORT=8000
DEBUG=false              # Disable auto-reload in production
ENVIRONMENT=production
LOG_LEVEL=INFO

# --- CORS ---
# Only allow known frontend origins (update as needed)
ALLOWED_ORIGINS=http://rebeldev.mistyk.media

# --- Auth (optional for public API protection) ---
REQUIRE_AUTH=false
# AUTH_TOKEN=your_secure_token_here

# --- OpenAI (uncomment + provide valid key if using) ---
# OPENAI_API_KEY=sk-xxxx

# --- Perplexity (optional) ---
# PERPLEXITY_API_KEY=pxy-xxxx

# --- Ollama ---
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_TIMEOUT=300

# --- Rate Limiting ---
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60
